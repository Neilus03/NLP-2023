{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPZ/E6Zi2cn7NmKWSOGNg1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neilus03/NLP-2023/blob/main/Python_for_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Python for NLP: An introduction to `nltk` library"
      ],
      "metadata": {
        "id": "-jTd7BWqbWoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook you'll be guided through a series of exercises, where you'll learn to make use of the nltk library and some of its functions for purposes like:\n",
        "\n",
        "\n",
        "*   Parsing\n",
        "*   Tokenization\n",
        "*   Tree generation\n",
        "*   ...\n",
        "\n",
        "Hope you enjoy it!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jQGDiUzxaeOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Set up**"
      ],
      "metadata": {
        "id": "51f8d0ybWjEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y73d7HB15ouS",
        "outputId": "43156d4d-5c99-4885-fc39-65a30d2d6188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('popular')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "7hTLdnpW5_d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "293d4295-4bcd-48af-fc30-db7bc2918d2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('maxent_treebank_pos_tagger')\n",
        "nltk.download('treebank')\n",
        "\n",
        "from nltk.draw.tree import draw_trees\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqw5bbC_8bsO",
        "outputId": "18c6fcd8-61e5-4dff-c540-5a68f368c613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJgaC0N45KqW",
        "outputId": "d5b6d9d5-312c-4cf5-de04-ba8029e6c810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['At', 'eight', \"o'clock\", 'on', 'Thursday', 'morning', 'Arthur', 'did', \"n't\", 'feel', 'very', 'good', '.']\n",
            "PoS: [('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'NN'), ('on', 'IN'), ('Thursday', 'NNP'), ('morning', 'NN'), ('Arthur', 'NNP'), ('did', 'VBD'), (\"n't\", 'RB'), ('feel', 'VB'), ('very', 'RB'), ('good', 'JJ'), ('.', '.')]\n",
            "['Good', 'muffins', 'cost', '$3.88', 'in', 'New', 'York', '.', 'Please', 'buy', 'me', 'two', 'of', 'them', '.', 'Thanks', '.']\n"
          ]
        }
      ],
      "source": [
        "sentence = \"At eight o'clock on Thursday morning Arthur didn't feel very good.\"\n",
        "tokens = nltk.word_tokenize(sentence) # Tokenize\n",
        "print(tokens)\n",
        "tagged = nltk.pos_tag(tokens) # PoS tagging\n",
        "print(\"PoS:\",tagged)\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "s = \"Good muffins cost $3.88\\nin New York. Please buy me two of them.\\n\\nThanks.\"\n",
        "tokenizer = RegexpTokenizer(r'\\w+|\\$[\\d\\.]+|\\S+')\n",
        "output = tokenizer.tokenize(s)\n",
        "print(output)\n",
        "from nltk.corpus import treebank\n",
        "t = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
        "#t.draw()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1. Exercise**\n",
        "\n"
      ],
      "metadata": {
        "id": "iE5N9l7K97bJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using the NLTK instructions, tokenize and compute the PoS of these sentences. Print the result:  \n",
        "\n",
        "*   `The Jamaica Observer reported that Usain Bolt broke the 100m record`\n",
        "*   `While hunting in Africa, I shot an elephant in my pajamas. How an elephant got into my pajamas I'll never know.`\n"
      ],
      "metadata": {
        "id": "qeOkN4Tm_j7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First sentence\n",
        "sentence1 = \"The Jamaica Observer reported that Usain Bolt broke the 100m record.\"\n",
        "tokens1 = nltk.word_tokenize(sentence1)\n",
        "PoS1 = nltk.pos_tag(tokens1)\n",
        "\n",
        "print(PoS1)\n",
        "\n",
        "# Second sentence\n",
        "sentence2 = \"While hunting in Africa, I shot an elephant in my pajamas. How an elephant got into my pajamas I'll never know.\"\n",
        "tokens2 = nltk.word_tokenize(sentence2)\n",
        "PoS2 = nltk.pos_tag(tokens2)\n",
        "\n",
        "print(PoS2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9SWZsnQ55Vl",
        "outputId": "657eb2f9-4993-4e15-f86b-f1ecae5aa32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('Jamaica', 'NNP'), ('Observer', 'NNP'), ('reported', 'VBD'), ('that', 'DT'), ('Usain', 'NNP'), ('Bolt', 'NNP'), ('broke', 'VBD'), ('the', 'DT'), ('100m', 'CD'), ('record', 'NN'), ('.', '.')]\n",
            "[('While', 'IN'), ('hunting', 'VBG'), ('in', 'IN'), ('Africa', 'NNP'), (',', ','), ('I', 'PRP'), ('shot', 'VBP'), ('an', 'DT'), ('elephant', 'NN'), ('in', 'IN'), ('my', 'PRP$'), ('pajamas', 'NN'), ('.', '.'), ('How', 'WRB'), ('an', 'DT'), ('elephant', 'JJ'), ('got', 'VBD'), ('into', 'IN'), ('my', 'PRP$'), ('pajamas', 'NN'), ('I', 'PRP'), (\"'ll\", 'MD'), ('never', 'RB'), ('know', 'VB'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Exercise:**"
      ],
      "metadata": {
        "id": "LzPQUZ2v-1Xx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the following code:\n",
        "\n",
        "\n",
        "```\n",
        "import nltk\n",
        "from nltk import CFG\n",
        "# Defining a grammar\n",
        "groucho_grammar = CFG.fromstring(\"\"\"\n",
        "S -> NP VP\n",
        "PP -> P NP\n",
        "NP -> Det N | Det N PP | 'I' | 'You'\n",
        "VP -> V NP | VP PP\n",
        "Det -> 'an' | 'my'\n",
        "N -> 'elephant' | 'pajamas'\n",
        "V -> 'shot'\n",
        "P -> 'in'\n",
        "\"\"\")\n",
        "# Printing the grammar\n",
        "print(\"START grammar:\",groucho_grammar.start())\n",
        "print(\"PRODUCTIONS grammar:\",groucho_grammar.productions())\n",
        "text = \"I shot an elephant in my pajamas\"\n",
        "text_tokens = nltk.word_tokenize(text)\n",
        "# Parsing the text\n",
        "parser = nltk.parse.chart.ChartParser(groucho_grammar,trace=2)\n",
        "trees = parser.parse(text_tokens)\n",
        "for t in trees:\n",
        "    print(t)\n",
        "```\n",
        "Modify the code to parse this list of texts (no need to parse Grouxoâ€™s sentence anymore):\n",
        "\n",
        "```\n",
        "mytexts = [\"John saw a man with my telescope\", \n",
        "           \"Alex kissed the dog\", \n",
        "           \"the man with the telescope ate a sandwich in the park\"]\n",
        "```\n",
        "Follow these steps:\n",
        "1. Create a CFG that can parse the sentences in mytexts.\n",
        "\n",
        "2. Make a loop for each sentence in mytexts:  \n",
        "    *   Parse the sentence.\n",
        "    *   Print the parse trees.\n",
        "    \n",
        "3. If the output consists of more than one parse tree, explain (maximum two sentences)\n",
        "why there is an ambiguity.\n",
        "\n"
      ],
      "metadata": {
        "id": "VJaBun1o_nRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import CFG\n",
        "\n",
        "# Defining a grammar\n",
        "my_grammar = CFG.fromstring(\"\"\"\n",
        "S -> NP VP\n",
        "PP -> P NP\n",
        "NP -> Det N | Det N PP | Det N PP PP | 'John' | 'Alex'\n",
        "VP -> V NP | VP PP | VP AdvP\n",
        "Det -> 'a' | 'my' | 'the'\n",
        "N -> 'man' | 'telescope' | 'dog' | 'sandwich' | 'park'\n",
        "V -> 'saw' | 'kissed' | 'ate'\n",
        "P -> 'with' | 'in'\n",
        "AdvP -> Adv PP\n",
        "Adv -> 'with'\n",
        "\"\"\")\n",
        "\n",
        "# List of texts to be parsed\n",
        "mytexts = [\"John saw a man with my telescope\", \n",
        "           \"Alex kissed the dog\", \n",
        "           \"the man with the telescope ate a sandwich in the park\"]\n",
        "\n",
        "# Printing the grammar\n",
        "print(\"START grammar:\",my_grammar.start())\n",
        "print(\"PRODUCTIONS grammar:\",my_grammar.productions())\n",
        "print (\"\\n\\n\\n\")\n",
        "\n",
        "for sentence in mytexts:\n",
        "    #printing the tree\n",
        "    print(\"Tree of the sentence :\", sentence)\n",
        "    parser = nltk.parse.chart.ChartParser(my_grammar,trace=2)\n",
        "    text_tokens = nltk.word_tokenize(sentence)\n",
        "    trees = parser.parse(text_tokens)\n",
        "    for t in trees:\n",
        "        print(t)\n",
        "    print(\"\\n\\n\\n\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWPiOery-1KP",
        "outputId": "d5e80537-281e-4ba0-dc77-256d39d010b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START grammar: S\n",
            "PRODUCTIONS grammar: [S -> NP VP, PP -> P NP, NP -> Det N, NP -> Det N PP, NP -> Det N PP PP, NP -> 'John', NP -> 'Alex', VP -> V NP, VP -> VP PP, VP -> VP AdvP, Det -> 'a', Det -> 'my', Det -> 'the', N -> 'man', N -> 'telescope', N -> 'dog', N -> 'sandwich', N -> 'park', V -> 'saw', V -> 'kissed', V -> 'ate', P -> 'with', P -> 'in', AdvP -> Adv PP, Adv -> 'with']\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tree of the sentence : John saw a man with my telescope\n",
            "|. John. saw .  a  . man . with.  my .teles.|\n",
            "Leaf Init Rule:\n",
            "|[-----]     .     .     .     .     .     .| [0:1] 'John'\n",
            "|.     [-----]     .     .     .     .     .| [1:2] 'saw'\n",
            "|.     .     [-----]     .     .     .     .| [2:3] 'a'\n",
            "|.     .     .     [-----]     .     .     .| [3:4] 'man'\n",
            "|.     .     .     .     [-----]     .     .| [4:5] 'with'\n",
            "|.     .     .     .     .     [-----]     .| [5:6] 'my'\n",
            "|.     .     .     .     .     .     [-----]| [6:7] 'telescope'\n",
            "Bottom Up Predict Combine Rule:\n",
            "|[-----]     .     .     .     .     .     .| [0:1] NP -> 'John' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|[----->     .     .     .     .     .     .| [0:1] S  -> NP * VP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     [-----]     .     .     .     .     .| [1:2] V  -> 'saw' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     [----->     .     .     .     .     .| [1:2] VP -> V * NP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     [-----]     .     .     .     .| [2:3] Det -> 'a' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     [----->     .     .     .     .| [2:3] NP -> Det * N\n",
            "|.     .     [----->     .     .     .     .| [2:3] NP -> Det * N PP\n",
            "|.     .     [----->     .     .     .     .| [2:3] NP -> Det * N PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     .     [-----]     .     .     .| [3:4] N  -> 'man' *\n",
            "Single Edge Fundamental Rule:\n",
            "|.     .     [-----------]     .     .     .| [2:4] NP -> Det N *\n",
            "|.     .     [----------->     .     .     .| [2:4] NP -> Det N * PP\n",
            "|.     .     [----------->     .     .     .| [2:4] NP -> Det N * PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     [----------->     .     .     .| [2:4] S  -> NP * VP\n",
            "Single Edge Fundamental Rule:\n",
            "|.     [-----------------]     .     .     .| [1:4] VP -> V NP *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     [----------------->     .     .     .| [1:4] VP -> VP * PP\n",
            "|.     [----------------->     .     .     .| [1:4] VP -> VP * AdvP\n",
            "Single Edge Fundamental Rule:\n",
            "|[-----------------------]     .     .     .| [0:4] S  -> NP VP *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     .     .     [-----]     .     .| [4:5] P  -> 'with' *\n",
            "|.     .     .     .     [-----]     .     .| [4:5] Adv -> 'with' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     .     .     [----->     .     .| [4:5] AdvP -> Adv * PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     .     .     [----->     .     .| [4:5] PP -> P * NP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     .     .     .     [-----]     .| [5:6] Det -> 'my' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     .     .     .     [----->     .| [5:6] NP -> Det * N\n",
            "|.     .     .     .     .     [----->     .| [5:6] NP -> Det * N PP\n",
            "|.     .     .     .     .     [----->     .| [5:6] NP -> Det * N PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     .     .     .     .     [-----]| [6:7] N  -> 'telescope' *\n",
            "Single Edge Fundamental Rule:\n",
            "|.     .     .     .     .     [-----------]| [5:7] NP -> Det N *\n",
            "|.     .     .     .     .     [----------->| [5:7] NP -> Det N * PP\n",
            "|.     .     .     .     .     [----------->| [5:7] NP -> Det N * PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     .     .     .     [----------->| [5:7] S  -> NP * VP\n",
            "Single Edge Fundamental Rule:\n",
            "|.     .     .     .     [-----------------]| [4:7] PP -> P NP *\n",
            "Single Edge Fundamental Rule:\n",
            "|.     .     [-----------------------------]| [2:7] NP -> Det N PP *\n",
            "|.     .     [----------------------------->| [2:7] NP -> Det N PP * PP\n",
            "|.     [-----------------------------------]| [1:7] VP -> VP PP *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     [----------------------------------->| [1:7] VP -> VP * PP\n",
            "|.     [----------------------------------->| [1:7] VP -> VP * AdvP\n",
            "Single Edge Fundamental Rule:\n",
            "|[=========================================]| [0:7] S  -> NP VP *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     [----------------------------->| [2:7] S  -> NP * VP\n",
            "Single Edge Fundamental Rule:\n",
            "|.     [-----------------------------------]| [1:7] VP -> V NP *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     [----------------------------------->| [1:7] VP -> VP * PP\n",
            "|.     [----------------------------------->| [1:7] VP -> VP * AdvP\n",
            "Single Edge Fundamental Rule:\n",
            "|[=========================================]| [0:7] S  -> NP VP *\n",
            "(S\n",
            "  (NP John)\n",
            "  (VP\n",
            "    (VP (V saw) (NP (Det a) (N man)))\n",
            "    (PP (P with) (NP (Det my) (N telescope)))))\n",
            "(S\n",
            "  (NP John)\n",
            "  (VP\n",
            "    (V saw)\n",
            "    (NP (Det a) (N man) (PP (P with) (NP (Det my) (N telescope))))))\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tree of the sentence : Alex kissed the dog\n",
            "|.   Alex  .  kissed .   the   .   dog   .|\n",
            "Leaf Init Rule:\n",
            "|[---------]         .         .         .| [0:1] 'Alex'\n",
            "|.         [---------]         .         .| [1:2] 'kissed'\n",
            "|.         .         [---------]         .| [2:3] 'the'\n",
            "|.         .         .         [---------]| [3:4] 'dog'\n",
            "Bottom Up Predict Combine Rule:\n",
            "|[---------]         .         .         .| [0:1] NP -> 'Alex' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|[--------->         .         .         .| [0:1] S  -> NP * VP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.         [---------]         .         .| [1:2] V  -> 'kissed' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.         [--------->         .         .| [1:2] VP -> V * NP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.         .         [---------]         .| [2:3] Det -> 'the' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.         .         [--------->         .| [2:3] NP -> Det * N\n",
            "|.         .         [--------->         .| [2:3] NP -> Det * N PP\n",
            "|.         .         [--------->         .| [2:3] NP -> Det * N PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.         .         .         [---------]| [3:4] N  -> 'dog' *\n",
            "Single Edge Fundamental Rule:\n",
            "|.         .         [-------------------]| [2:4] NP -> Det N *\n",
            "|.         .         [------------------->| [2:4] NP -> Det N * PP\n",
            "|.         .         [------------------->| [2:4] NP -> Det N * PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.         .         [------------------->| [2:4] S  -> NP * VP\n",
            "Single Edge Fundamental Rule:\n",
            "|.         [-----------------------------]| [1:4] VP -> V NP *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.         [----------------------------->| [1:4] VP -> VP * PP\n",
            "|.         [----------------------------->| [1:4] VP -> VP * AdvP\n",
            "Single Edge Fundamental Rule:\n",
            "|[=======================================]| [0:4] S  -> NP VP *\n",
            "(S (NP Alex) (VP (V kissed) (NP (Det the) (N dog))))\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tree of the sentence : the man with the telescope ate a sandwich in the park\n",
            "|.the.man.wit.the.tel.ate. a .san. in.the.par.|\n",
            "Leaf Init Rule:\n",
            "|[---]   .   .   .   .   .   .   .   .   .   .| [0:1] 'the'\n",
            "|.   [---]   .   .   .   .   .   .   .   .   .| [1:2] 'man'\n",
            "|.   .   [---]   .   .   .   .   .   .   .   .| [2:3] 'with'\n",
            "|.   .   .   [---]   .   .   .   .   .   .   .| [3:4] 'the'\n",
            "|.   .   .   .   [---]   .   .   .   .   .   .| [4:5] 'telescope'\n",
            "|.   .   .   .   .   [---]   .   .   .   .   .| [5:6] 'ate'\n",
            "|.   .   .   .   .   .   [---]   .   .   .   .| [6:7] 'a'\n",
            "|.   .   .   .   .   .   .   [---]   .   .   .| [7:8] 'sandwich'\n",
            "|.   .   .   .   .   .   .   .   [---]   .   .| [8:9] 'in'\n",
            "|.   .   .   .   .   .   .   .   .   [---]   .| [9:10] 'the'\n",
            "|.   .   .   .   .   .   .   .   .   .   [---]| [10:11] 'park'\n",
            "Bottom Up Predict Combine Rule:\n",
            "|[---]   .   .   .   .   .   .   .   .   .   .| [0:1] Det -> 'the' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|[--->   .   .   .   .   .   .   .   .   .   .| [0:1] NP -> Det * N\n",
            "|[--->   .   .   .   .   .   .   .   .   .   .| [0:1] NP -> Det * N PP\n",
            "|[--->   .   .   .   .   .   .   .   .   .   .| [0:1] NP -> Det * N PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   [---]   .   .   .   .   .   .   .   .   .| [1:2] N  -> 'man' *\n",
            "Single Edge Fundamental Rule:\n",
            "|[-------]   .   .   .   .   .   .   .   .   .| [0:2] NP -> Det N *\n",
            "|[------->   .   .   .   .   .   .   .   .   .| [0:2] NP -> Det N * PP\n",
            "|[------->   .   .   .   .   .   .   .   .   .| [0:2] NP -> Det N * PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|[------->   .   .   .   .   .   .   .   .   .| [0:2] S  -> NP * VP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   [---]   .   .   .   .   .   .   .   .| [2:3] P  -> 'with' *\n",
            "|.   .   [---]   .   .   .   .   .   .   .   .| [2:3] Adv -> 'with' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   [--->   .   .   .   .   .   .   .   .| [2:3] AdvP -> Adv * PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   [--->   .   .   .   .   .   .   .   .| [2:3] PP -> P * NP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   [---]   .   .   .   .   .   .   .| [3:4] Det -> 'the' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   [--->   .   .   .   .   .   .   .| [3:4] NP -> Det * N\n",
            "|.   .   .   [--->   .   .   .   .   .   .   .| [3:4] NP -> Det * N PP\n",
            "|.   .   .   [--->   .   .   .   .   .   .   .| [3:4] NP -> Det * N PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   .   [---]   .   .   .   .   .   .| [4:5] N  -> 'telescope' *\n",
            "Single Edge Fundamental Rule:\n",
            "|.   .   .   [-------]   .   .   .   .   .   .| [3:5] NP -> Det N *\n",
            "|.   .   .   [------->   .   .   .   .   .   .| [3:5] NP -> Det N * PP\n",
            "|.   .   .   [------->   .   .   .   .   .   .| [3:5] NP -> Det N * PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   [------->   .   .   .   .   .   .| [3:5] S  -> NP * VP\n",
            "Single Edge Fundamental Rule:\n",
            "|.   .   [-----------]   .   .   .   .   .   .| [2:5] PP -> P NP *\n",
            "Single Edge Fundamental Rule:\n",
            "|[-------------------]   .   .   .   .   .   .| [0:5] NP -> Det N PP *\n",
            "|[------------------->   .   .   .   .   .   .| [0:5] NP -> Det N PP * PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|[------------------->   .   .   .   .   .   .| [0:5] S  -> NP * VP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   .   .   [---]   .   .   .   .   .| [5:6] V  -> 'ate' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   .   .   [--->   .   .   .   .   .| [5:6] VP -> V * NP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   .   .   .   [---]   .   .   .   .| [6:7] Det -> 'a' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   .   .   .   [--->   .   .   .   .| [6:7] NP -> Det * N\n",
            "|.   .   .   .   .   .   [--->   .   .   .   .| [6:7] NP -> Det * N PP\n",
            "|.   .   .   .   .   .   [--->   .   .   .   .| [6:7] NP -> Det * N PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   .   .   .   .   [---]   .   .   .| [7:8] N  -> 'sandwich' *\n",
            "Single Edge Fundamental Rule:\n",
            "|.   .   .   .   .   .   [-------]   .   .   .| [6:8] NP -> Det N *\n",
            "|.   .   .   .   .   .   [------->   .   .   .| [6:8] NP -> Det N * PP\n",
            "|.   .   .   .   .   .   [------->   .   .   .| [6:8] NP -> Det N * PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   .   .   .   [------->   .   .   .| [6:8] S  -> NP * VP\n",
            "Single Edge Fundamental Rule:\n",
            "|.   .   .   .   .   [-----------]   .   .   .| [5:8] VP -> V NP *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   .   .   [----------->   .   .   .| [5:8] VP -> VP * PP\n",
            "|.   .   .   .   .   [----------->   .   .   .| [5:8] VP -> VP * AdvP\n",
            "Single Edge Fundamental Rule:\n",
            "|.   .   .   [-------------------]   .   .   .| [3:8] S  -> NP VP *\n",
            "|[-------------------------------]   .   .   .| [0:8] S  -> NP VP *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   .   .   .   .   .   [---]   .   .| [8:9] P  -> 'in' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   .   .   .   .   .   [--->   .   .| [8:9] PP -> P * NP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   .   .   .   .   .   .   [---]   .| [9:10] Det -> 'the' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   .   .   .   .   .   .   [--->   .| [9:10] NP -> Det * N\n",
            "|.   .   .   .   .   .   .   .   .   [--->   .| [9:10] NP -> Det * N PP\n",
            "|.   .   .   .   .   .   .   .   .   [--->   .| [9:10] NP -> Det * N PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   .   .   .   .   .   .   .   [---]| [10:11] N  -> 'park' *\n",
            "Single Edge Fundamental Rule:\n",
            "|.   .   .   .   .   .   .   .   .   [-------]| [9:11] NP -> Det N *\n",
            "|.   .   .   .   .   .   .   .   .   [------->| [9:11] NP -> Det N * PP\n",
            "|.   .   .   .   .   .   .   .   .   [------->| [9:11] NP -> Det N * PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   .   .   .   .   .   .   [------->| [9:11] S  -> NP * VP\n",
            "Single Edge Fundamental Rule:\n",
            "|.   .   .   .   .   .   .   .   [-----------]| [8:11] PP -> P NP *\n",
            "Single Edge Fundamental Rule:\n",
            "|.   .   .   .   .   .   [-------------------]| [6:11] NP -> Det N PP *\n",
            "|.   .   .   .   .   .   [------------------->| [6:11] NP -> Det N PP * PP\n",
            "|.   .   .   .   .   [-----------------------]| [5:11] VP -> VP PP *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   .   .   [----------------------->| [5:11] VP -> VP * PP\n",
            "|.   .   .   .   .   [----------------------->| [5:11] VP -> VP * AdvP\n",
            "Single Edge Fundamental Rule:\n",
            "|.   .   .   [-------------------------------]| [3:11] S  -> NP VP *\n",
            "|[===========================================]| [0:11] S  -> NP VP *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   .   .   .   [------------------->| [6:11] S  -> NP * VP\n",
            "Single Edge Fundamental Rule:\n",
            "|.   .   .   .   .   [-----------------------]| [5:11] VP -> V NP *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.   .   .   .   .   [----------------------->| [5:11] VP -> VP * PP\n",
            "|.   .   .   .   .   [----------------------->| [5:11] VP -> VP * AdvP\n",
            "Single Edge Fundamental Rule:\n",
            "|.   .   .   [-------------------------------]| [3:11] S  -> NP VP *\n",
            "|[===========================================]| [0:11] S  -> NP VP *\n",
            "(S\n",
            "  (NP (Det the) (N man) (PP (P with) (NP (Det the) (N telescope))))\n",
            "  (VP\n",
            "    (VP (V ate) (NP (Det a) (N sandwich)))\n",
            "    (PP (P in) (NP (Det the) (N park)))))\n",
            "(S\n",
            "  (NP (Det the) (N man) (PP (P with) (NP (Det the) (N telescope))))\n",
            "  (VP\n",
            "    (V ate)\n",
            "    (NP (Det a) (N sandwich) (PP (P in) (NP (Det the) (N park))))))\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Explanation of ambiguities:**\n",
        "\n"
      ],
      "metadata": {
        "id": "aue-Gqq3My_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **John saw a man with my telescope**"
      ],
      "metadata": {
        "id": "Bg8aYlObQuPz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####In the phrase **John saw a man with my telescope** there are two possible trees:\n",
        "\n",
        "\n",
        "1. \n",
        "\n",
        "\n",
        "```\n",
        "(S\n",
        "(NP John)\n",
        "(VP\n",
        "    (VP (V saw) (NP (Det a) (N man)))\n",
        "    (PP (P with) (NP (Det my) (N telescope)))))\n",
        "```\n",
        "\n",
        "We can conclude that the meaning is that John saw a man, and when John saw that man, John was using my telescope to see it.\n",
        "\n",
        "2. \n",
        "\n",
        "\n",
        "```\n",
        "(S\n",
        "(NP John)\n",
        "(VP\n",
        "    (V saw)\n",
        "    (NP (Det a) (N man) (PP (P with) (NP (Det my) (N telescope))))))\n",
        "\n",
        "```\n",
        "\n",
        "Here instead, the meaning would be that John saw a man, and that the man that john saw was with my telescope."
      ],
      "metadata": {
        "id": "1xCPWj9JOrkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **the man with the telescope ate a sandwich in the park**"
      ],
      "metadata": {
        "id": "L9Tx-MtqQx27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### In the phrase **the man with the telescope ate a sandwich in the park** there are two possible trees:\n",
        "\n",
        "\n",
        "1. \n",
        "\n",
        "\n",
        "```\n",
        "(S\n",
        "  (NP (Det the) (N man) (PP (P with) (NP (Det the) (N telescope))))\n",
        "  (VP\n",
        "    (VP (V ate) (NP (Det a) (N sandwich)))\n",
        "    (PP (P in) (NP (Det the) (N park)))))\n",
        "```\n",
        "The first tree shows that the PP \"with the telescope\" modifies the NP \"the man\"\n",
        "\n",
        "2. \n",
        "\n",
        "\n",
        "```\n",
        "(S\n",
        "  (NP (Det the) (N man) (PP (P with) (NP (Det the) (N telescope))))\n",
        "  (VP\n",
        "    (V ate)\n",
        "    (NP (Det a) (N sandwich) (PP (P in) (NP (Det the) (N park))))))\n",
        "\n",
        "```\n",
        "\n",
        "The second tree shows that the PP \"in the park\" modifies the NP \"a sandwich\". \n",
        "\n",
        "\n",
        "The meaning remains the same in both."
      ],
      "metadata": {
        "id": "TKRMSvtNQMf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**3. Exercise**"
      ],
      "metadata": {
        "id": "MXdintE8G_6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Write an example of a sentence that, although it is syntactically correct in Englishand uses the lexicon of the previous grammar, it cannot be parsed by the previous defined grammar."
      ],
      "metadata": {
        "id": "tvuVmNK2HUCr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **\"John with my telescope saw a man\"**:\n",
        "\n",
        "    The sentence is grammatically correct in English and includes words from the lexicon used to define the grammar. However, it cannot be parsed by the previously defined grammar because it violates the order of constituents specified in the grammar rules.\n",
        "    \n",
        "     The rule for a sentence (S) specifies that it must consist of a noun phrase (NP) followed by a verb phrase (VP). The rule for a verb phrase (VP) specifies that it can consist of a verb (V) followed by a noun phrase (NP) or a VP followed by a prepositional phrase (PP) or an adverb phrase (AdvP). \\\n",
        "     \n",
        "     However, in the given sentence, the PP \"with my telescope\" appears before the VP \"saw a man\", while the grammar rules dictate that the prepositional phrase should follow the verb phrase. Then, the sentence cannot be parsed by the previously defined grammar."
      ],
      "metadata": {
        "id": "QxR6SXdZINTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check if it would be possible to parse it or not:"
      ],
      "metadata": {
        "id": "BdTqWiGxVRyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import CFG\n",
        "\n",
        "# Defining a grammar\n",
        "my_grammar = CFG.fromstring(\"\"\"\n",
        "S -> NP VP\n",
        "PP -> P NP\n",
        "NP -> Det N | Det N PP | Det N PP PP | 'John' | 'Alex'\n",
        "VP -> V NP | VP PP | VP AdvP\n",
        "Det -> 'a' | 'my' | 'the'\n",
        "N -> 'man' | 'telescope' | 'dog' | 'sandwich' | 'park'\n",
        "V -> 'saw' | 'kissed' | 'ate'\n",
        "P -> 'with' | 'in'\n",
        "AdvP -> Adv PP\n",
        "Adv -> 'with'\n",
        "\"\"\")\n",
        "\n",
        "# List of texts to be parsed\n",
        "mytexts = [\"John with my telescope saw a man\"]\n",
        "\n",
        "# Printing the grammar\n",
        "print(\"START grammar:\",my_grammar.start())\n",
        "print(\"PRODUCTIONS grammar:\",my_grammar.productions())\n",
        "print (\"\\n\\n\\n\")\n",
        "\n",
        "for sentence in mytexts:\n",
        "    #printing the tree\n",
        "    print(\"Tree of the sentence :\", sentence)\n",
        "    parser = nltk.parse.chart.ChartParser(my_grammar,trace=2)\n",
        "    text_tokens = nltk.word_tokenize(sentence)\n",
        "    trees = parser.parse(text_tokens)\n",
        "    for t in trees:\n",
        "        print(t)\n",
        "    print(\"\\n\\n\\n\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuABGhqJUx_7",
        "outputId": "41d33037-8bdc-4b76-bc81-90fcecc1065e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START grammar: S\n",
            "PRODUCTIONS grammar: [S -> NP VP, PP -> P NP, NP -> Det N, NP -> Det N PP, NP -> Det N PP PP, NP -> 'John', NP -> 'Alex', VP -> V NP, VP -> VP PP, VP -> VP AdvP, Det -> 'a', Det -> 'my', Det -> 'the', N -> 'man', N -> 'telescope', N -> 'dog', N -> 'sandwich', N -> 'park', V -> 'saw', V -> 'kissed', V -> 'ate', P -> 'with', P -> 'in', AdvP -> Adv PP, Adv -> 'with']\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tree of the sentence : John with my telescope saw a man\n",
            "|. John. with.  my .teles. saw .  a  . man .|\n",
            "Leaf Init Rule:\n",
            "|[-----]     .     .     .     .     .     .| [0:1] 'John'\n",
            "|.     [-----]     .     .     .     .     .| [1:2] 'with'\n",
            "|.     .     [-----]     .     .     .     .| [2:3] 'my'\n",
            "|.     .     .     [-----]     .     .     .| [3:4] 'telescope'\n",
            "|.     .     .     .     [-----]     .     .| [4:5] 'saw'\n",
            "|.     .     .     .     .     [-----]     .| [5:6] 'a'\n",
            "|.     .     .     .     .     .     [-----]| [6:7] 'man'\n",
            "Bottom Up Predict Combine Rule:\n",
            "|[-----]     .     .     .     .     .     .| [0:1] NP -> 'John' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|[----->     .     .     .     .     .     .| [0:1] S  -> NP * VP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     [-----]     .     .     .     .     .| [1:2] P  -> 'with' *\n",
            "|.     [-----]     .     .     .     .     .| [1:2] Adv -> 'with' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     [----->     .     .     .     .     .| [1:2] AdvP -> Adv * PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     [----->     .     .     .     .     .| [1:2] PP -> P * NP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     [-----]     .     .     .     .| [2:3] Det -> 'my' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     [----->     .     .     .     .| [2:3] NP -> Det * N\n",
            "|.     .     [----->     .     .     .     .| [2:3] NP -> Det * N PP\n",
            "|.     .     [----->     .     .     .     .| [2:3] NP -> Det * N PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     .     [-----]     .     .     .| [3:4] N  -> 'telescope' *\n",
            "Single Edge Fundamental Rule:\n",
            "|.     .     [-----------]     .     .     .| [2:4] NP -> Det N *\n",
            "|.     .     [----------->     .     .     .| [2:4] NP -> Det N * PP\n",
            "|.     .     [----------->     .     .     .| [2:4] NP -> Det N * PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     [----------->     .     .     .| [2:4] S  -> NP * VP\n",
            "Single Edge Fundamental Rule:\n",
            "|.     [-----------------]     .     .     .| [1:4] PP -> P NP *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     .     .     [-----]     .     .| [4:5] V  -> 'saw' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     .     .     [----->     .     .| [4:5] VP -> V * NP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     .     .     .     [-----]     .| [5:6] Det -> 'a' *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     .     .     .     [----->     .| [5:6] NP -> Det * N\n",
            "|.     .     .     .     .     [----->     .| [5:6] NP -> Det * N PP\n",
            "|.     .     .     .     .     [----->     .| [5:6] NP -> Det * N PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     .     .     .     .     [-----]| [6:7] N  -> 'man' *\n",
            "Single Edge Fundamental Rule:\n",
            "|.     .     .     .     .     [-----------]| [5:7] NP -> Det N *\n",
            "|.     .     .     .     .     [----------->| [5:7] NP -> Det N * PP\n",
            "|.     .     .     .     .     [----------->| [5:7] NP -> Det N * PP PP\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     .     .     .     [----------->| [5:7] S  -> NP * VP\n",
            "Single Edge Fundamental Rule:\n",
            "|.     .     .     .     [-----------------]| [4:7] VP -> V NP *\n",
            "Bottom Up Predict Combine Rule:\n",
            "|.     .     .     .     [----------------->| [4:7] VP -> VP * PP\n",
            "|.     .     .     .     [----------------->| [4:7] VP -> VP * AdvP\n",
            "Single Edge Fundamental Rule:\n",
            "|.     .     [-----------------------------]| [2:7] S  -> NP VP *\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, there's no possible tree because the rules of grammar are not respected."
      ],
      "metadata": {
        "id": "o1JMeCyhVJMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Exercise**"
      ],
      "metadata": {
        "id": "ByYc06bsLO95"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Propose how to augment the previous parser to deal with sentences that may be incorrect, for example, containing spelling errors or mistakes arising from automatic speech recognition or handwritten text recognition (maximum 3 sentences)."
      ],
      "metadata": {
        "id": "2qnnXFVwMpzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To augment the previous parser to deal with incorrect sentences, we can consider the following approaches:\n",
        "\n",
        "\n",
        "\n",
        "*   **Error detection:** We can implement a module that detects errors in the input sentence before it is passed to the parser. This module can use spelling checkers or other machine learning models to identify possible errors and suggest corrections. If an error is detected, the user can be prompted to confirm or correct the error before proceeding. \n",
        "\n",
        "*   **Robust parsing:** We can improve the parser's robustness by using techniques such as probabilistic parsing or error-tolerant parsing. These techniques allow the parser to handle uncertain or incomplete input by assigning probabilities to different parse trees or by generating multiple possible parse trees. The most likely or the most appropriate parse tree can then be selected based on context or user feedback.\n",
        "\n",
        "*   **Data augmentation:** We can augment the training data for the parser with examples of sentences containing errors or mistakes. This can help the parser learn to handle common errors and variations in the input. We can also use data augmentation techniques such as noise injection or random perturbations to simulate different types of errors and improve the parser's robustness.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZhQAnUPnUD8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5. Exercise**"
      ],
      "metadata": {
        "id": "ZYx_yWa5Vbfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the following code:\n",
        "\n",
        "\n",
        "```\n",
        "import nltk\n",
        "from nltk import PCFG\n",
        "pcfg1 = PCFG.fromstring(\"\"\"\n",
        "S -> NP VP [1.0]\n",
        "NP -> Det N [0.5] | NP PP [0.25] | 'John' [0.1] | 'I' [0.15]\n",
        "Det -> 'the' [0.8] | 'a' [0.2]\n",
        "N -> 'man' [0.5] | 'telescope' [0.5]\n",
        "VP -> VP PP [0.1] | V NP [0.7] | V [0.2]\n",
        "V -> 'ate' [0.35] | 'saw' [0.65]\n",
        "PP -> P NP [1.0]\n",
        "P -> 'with' [0.61] | 'in' [0.39]\n",
        "\"\"\")\n",
        "print(pcfg1)\n",
        "text = \"I saw the man with a telescope\"\n",
        "text_tokens = nltk.word_tokenize(text)\n",
        "viterbi_parser = nltk.ViterbiParser(pcfg1,trace=3)\n",
        "trees = viterbi_parser.parse(text_tokens)\n",
        "for tree in trees:\n",
        "    print(tree)\n",
        "    tree.draw()\n",
        "```\n",
        "\n",
        "Execute this code, modifying the parameter trace (values from 1 to 3). Explain the\n",
        "differences. Print the parsing probability of the sentence \"I saw the man with a\n",
        "telescope\". Print the tree."
      ],
      "metadata": {
        "id": "xNW4R14rWCfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Just a simple function for better visualization, just run it\n",
        "def print_spaces(trace_val):\n",
        "    print(\"\\n------------------------------------------\\n\")\n",
        "    print(\"With trace = \"+ str(trace_val)+\":\")\n",
        "    print()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gdWjQLzuhYHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import PCFG\n",
        "\n",
        "pcfg1 = PCFG.fromstring(\"\"\"\n",
        "S -> NP VP [1.0]\n",
        "NP -> Det N [0.5] | NP PP [0.25] | 'John' [0.1] | 'I' [0.15]\n",
        "Det -> 'the' [0.8] | 'a' [0.2]\n",
        "N -> 'man' [0.5] | 'telescope' [0.5]\n",
        "VP -> VP PP [0.1] | V NP [0.7] | V [0.2]\n",
        "V -> 'ate' [0.35] | 'saw' [0.65]\n",
        "PP -> P NP [1.0]\n",
        "P -> 'with' [0.61] | 'in' [0.39]\n",
        "\"\"\")\n",
        "\n",
        "print(pcfg1)\n",
        "\n",
        "text = \"I saw the man with a telescope\"\n",
        "text_tokens = nltk.word_tokenize(text)\n",
        "\n",
        "#go changing the trace value and check the result\n",
        "\n",
        "# trace = 1\n",
        "\n",
        "print_spaces(trace_val = 1)\n",
        "\n",
        "viterbi_parser = nltk.ViterbiParser(pcfg1, trace=1)\n",
        "trees = viterbi_parser.parse(text_tokens)\n",
        "for tree in trees:\n",
        "    print(\"\\nParsing probability:\", tree.prob())\n",
        "    #tree.draw()\n",
        "\n",
        "print_spaces(trace_val = 2)\n",
        "\n",
        "# trace = 2\n",
        "viterbi_parser = nltk.ViterbiParser(pcfg1, trace=2)\n",
        "trees = viterbi_parser.parse(text_tokens)\n",
        "for tree in trees:\n",
        "    print(\"\\nParsing probability:\", tree.prob())\n",
        "    print(tree)\n",
        "    #tree.draw()\n",
        "\n",
        "print_spaces(trace_val = 3)\n",
        "\n",
        "# trace = 3\n",
        "viterbi_parser = nltk.ViterbiParser(pcfg1, trace=3)\n",
        "trees = viterbi_parser.parse(text_tokens)\n",
        "for tree in trees:\n",
        "    print(\"\\nParsing probability:\", tree.prob())\n",
        "    print(tree)\n",
        "    #tree.draw()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXrbzFRGf_v3",
        "outputId": "0f67f9d2-971a-4a7f-bb34-b9b76ed957cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grammar with 17 productions (start state = S)\n",
            "    S -> NP VP [1.0]\n",
            "    NP -> Det N [0.5]\n",
            "    NP -> NP PP [0.25]\n",
            "    NP -> 'John' [0.1]\n",
            "    NP -> 'I' [0.15]\n",
            "    Det -> 'the' [0.8]\n",
            "    Det -> 'a' [0.2]\n",
            "    N -> 'man' [0.5]\n",
            "    N -> 'telescope' [0.5]\n",
            "    VP -> VP PP [0.1]\n",
            "    VP -> V NP [0.7]\n",
            "    VP -> V [0.2]\n",
            "    V -> 'ate' [0.35]\n",
            "    V -> 'saw' [0.65]\n",
            "    PP -> P NP [1.0]\n",
            "    P -> 'with' [0.61]\n",
            "    P -> 'in' [0.39]\n",
            "\n",
            "------------------------------------------\n",
            "\n",
            "With trace = 1:\n",
            "\n",
            "Inserting tokens into the most likely constituents table...\n",
            "Finding the most likely constituents spanning 1 text elements...\n",
            "Finding the most likely constituents spanning 2 text elements...\n",
            "Finding the most likely constituents spanning 3 text elements...\n",
            "Finding the most likely constituents spanning 4 text elements...\n",
            "Finding the most likely constituents spanning 5 text elements...\n",
            "Finding the most likely constituents spanning 6 text elements...\n",
            "Finding the most likely constituents spanning 7 text elements...\n",
            "\n",
            "Parsing probability: 0.00010408124999999999\n",
            "\n",
            "------------------------------------------\n",
            "\n",
            "With trace = 2:\n",
            "\n",
            "Inserting tokens into the most likely constituents table...\n",
            "   Insert: |=......| I\n",
            "   Insert: |.=.....| saw\n",
            "   Insert: |..=....| the\n",
            "   Insert: |...=...| man\n",
            "   Insert: |....=..| with\n",
            "   Insert: |.....=.| a\n",
            "   Insert: |......=| telescope\n",
            "Finding the most likely constituents spanning 1 text elements...\n",
            "   Insert: |=......| NP -> 'I' [0.15]\n",
            "   Insert: |.=.....| V -> 'saw' [0.65]\n",
            "   Insert: |.=.....| VP -> V [0.2]\n",
            "   Insert: |..=....| Det -> 'the' [0.8]\n",
            "   Insert: |...=...| N -> 'man' [0.5]\n",
            "   Insert: |....=..| P -> 'with' [0.61]\n",
            "   Insert: |.....=.| Det -> 'a' [0.2]\n",
            "   Insert: |......=| N -> 'telescope' [0.5]\n",
            "Finding the most likely constituents spanning 2 text elements...\n",
            "   Insert: |==.....| S -> NP VP [1.0]\n",
            "   Insert: |..==...| NP -> Det N [0.5]\n",
            "   Insert: |.....==| NP -> Det N [0.5]\n",
            "Finding the most likely constituents spanning 3 text elements...\n",
            "   Insert: |.===...| VP -> V NP [0.7]\n",
            "   Insert: |....===| PP -> P NP [1.0]\n",
            "Finding the most likely constituents spanning 4 text elements...\n",
            "   Insert: |====...| S -> NP VP [1.0]\n",
            "Finding the most likely constituents spanning 5 text elements...\n",
            "   Insert: |..=====| NP -> NP PP [0.25]\n",
            "Finding the most likely constituents spanning 6 text elements...\n",
            "   Insert: |.======| VP -> VP PP [0.1]\n",
            "   Insert: |.======| VP -> V NP [0.7]\n",
            "  Discard: |.======| VP -> VP PP [0.1]\n",
            "Finding the most likely constituents spanning 7 text elements...\n",
            "   Insert: |=======| S -> NP VP [1.0]\n",
            "\n",
            "Parsing probability: 0.00010408124999999999\n",
            "(S\n",
            "  (NP I)\n",
            "  (VP\n",
            "    (V saw)\n",
            "    (NP\n",
            "      (NP (Det the) (N man))\n",
            "      (PP (P with) (NP (Det a) (N telescope)))))) (p=0.000104081)\n",
            "\n",
            "------------------------------------------\n",
            "\n",
            "With trace = 3:\n",
            "\n",
            "Inserting tokens into the most likely constituents table...\n",
            "   Insert: |=......| I\n",
            "   Insert: |.=.....| saw\n",
            "   Insert: |..=....| the\n",
            "   Insert: |...=...| man\n",
            "   Insert: |....=..| with\n",
            "   Insert: |.....=.| a\n",
            "   Insert: |......=| telescope\n",
            "Finding the most likely constituents spanning 1 text elements...\n",
            "   Insert: |=......| NP -> 'I' [0.15]               0.1500000000 \n",
            "   Insert: |.=.....| V -> 'saw' [0.65]              0.6500000000 \n",
            "   Insert: |.=.....| VP -> V [0.2]                  0.1300000000 \n",
            "   Insert: |..=....| Det -> 'the' [0.8]             0.8000000000 \n",
            "   Insert: |...=...| N -> 'man' [0.5]               0.5000000000 \n",
            "   Insert: |....=..| P -> 'with' [0.61]             0.6100000000 \n",
            "   Insert: |.....=.| Det -> 'a' [0.2]               0.2000000000 \n",
            "   Insert: |......=| N -> 'telescope' [0.5]         0.5000000000 \n",
            "Finding the most likely constituents spanning 2 text elements...\n",
            "   Insert: |==.....| S -> NP VP [1.0]               0.0195000000 \n",
            "   Insert: |..==...| NP -> Det N [0.5]              0.2000000000 \n",
            "   Insert: |.....==| NP -> Det N [0.5]              0.0500000000 \n",
            "Finding the most likely constituents spanning 3 text elements...\n",
            "   Insert: |.===...| VP -> V NP [0.7]               0.0910000000 \n",
            "   Insert: |....===| PP -> P NP [1.0]               0.0305000000 \n",
            "Finding the most likely constituents spanning 4 text elements...\n",
            "   Insert: |====...| S -> NP VP [1.0]               0.0136500000 \n",
            "Finding the most likely constituents spanning 5 text elements...\n",
            "   Insert: |..=====| NP -> NP PP [0.25]             0.0015250000 \n",
            "Finding the most likely constituents spanning 6 text elements...\n",
            "   Insert: |.======| VP -> VP PP [0.1]              0.0002775500 \n",
            "   Insert: |.======| VP -> V NP [0.7]               0.0006938750 \n",
            "  Discard: |.======| VP -> VP PP [0.1]              0.0002775500 \n",
            "Finding the most likely constituents spanning 7 text elements...\n",
            "   Insert: |=======| S -> NP VP [1.0]               0.0001040812 \n",
            "\n",
            "Parsing probability: 0.00010408124999999999\n",
            "(S\n",
            "  (NP I)\n",
            "  (VP\n",
            "    (V saw)\n",
            "    (NP\n",
            "      (NP (Det the) (N man))\n",
            "      (PP (P with) (NP (Det a) (N telescope)))))) (p=0.000104081)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can observe above, the trace parameter in `nltk.ViterbiParser` determines the amount of information displayed during the parsing process. The higher the value, the more information is displayed.\n",
        "\n",
        "\n",
        "\n",
        "*   When `trace` is set to `1`, only the parse probabilities are displayed. \n",
        "*   When `trace` is set to `2`, the parse probabilities and the productions used to generate the parse are displayed.\n",
        "*   When `trace` is set to `3`, the parse probabilities, the productions used to generate the parse, and the intermediate steps of the parsing algorithm are displayed."
      ],
      "metadata": {
        "id": "kER4aQxeihVz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tM_jh0j5j2vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**6. Exercise**"
      ],
      "metadata": {
        "id": "QHqb3QV0lMF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the sentence has two possible parse trees, modify the grammar probabilities to\n",
        "force the other parsing tree to be more probable. Print the new probability and the\n",
        "tree.\n",
        "\n",
        "Given the following code for learning and using a grammar:\n",
        "\n",
        "```\n",
        "import nltk\n",
        "from nltk.corpus import treebank\n",
        "\n",
        "productions=[]\n",
        "S=nltk.Nonterminal('S')\n",
        "\n",
        "for f in treebank.fileids():\n",
        "    for tree in treebank.parsed_sents(f):\n",
        "        productions+=tree.productions()\n",
        "\n",
        "grammar=nltk.induce_pcfg(S,productions)\n",
        "\n",
        "for p in grammar.productions()[1:25]:\n",
        "    print(p)\n",
        "\n",
        "myparser = nltk.ViterbiParser(grammar,1)\n",
        "text = \"the boy jumps over the board\"\n",
        "mytokens = nltk.word_tokenize(text)\n",
        "myparsing, = myparser.parse(mytokens)\n",
        "\n",
        "print(myparsing)\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I-ogo3t0lLMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answer:\n",
        "To modify the grammar probabilities to force the other parsing tree to be more probable, I adjusted the probabilities of the productions that lead to that tree. In this case, we need to increase the probability of the production VP -> V NP [0.9], which is responsible for the tree where \"with a telescope\" is attached to \"saw\" rather than \"man\". We can decrease the probabilities of the other VP productions to compensate for this change.\n",
        "\n",
        "I also changed some other probabilities in my grammar to enhance the likelihood of the other tree."
      ],
      "metadata": {
        "id": "wg3baiDjmYft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "previous grammar probabilities:\n",
        "\n",
        "```\n",
        "S -> NP VP [1.0]\n",
        "NP -> Det N [0.5] | NP PP [0.25] | 'John' [0.1] | 'I' [0.15]\n",
        "Det -> 'the' [0.8] | 'a' [0.2]\n",
        "N -> 'man' [0.5] | 'telescope' [0.5]\n",
        "VP -> VP PP [0.1] | V NP [0.7] | V [0.2]\n",
        "V -> 'ate' [0.35] | 'saw' [0.65]\n",
        "PP -> P NP [1.0]\n",
        "P -> 'with' [0.61] | 'in' [0.39]\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "New grammar probabilities to enhance the likelihood of the other tree:\n",
        "\n",
        "```\n",
        "S -> NP VP [1.0]\n",
        "NP -> Det N [0.4] | NP PP [0.25] | 'John' [0.05] | 'I' [0.3]\n",
        "Det -> 'the' [0.8] | 'a' [0.2]\n",
        "N -> 'man' [0.5] | 'telescope' [0.5]\n",
        "VP -> VP PP [0.05] | V NP [0.9] | V [0.05]\n",
        "V -> 'ate' [0.2] | 'saw' [0.8]\n",
        "PP -> P NP [1.0]\n",
        "P -> 'with' [0.70] | 'in' [0.30]\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wWlTY34WnCXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import PCFG\n",
        "\n",
        "pcfg2 = PCFG.fromstring(\"\"\"\n",
        "S -> NP VP [1.0]\n",
        "NP -> Det N [0.4] | NP PP [0.25] | 'John' [0.05] | 'I' [0.3]\n",
        "Det -> 'the' [0.8] | 'a' [0.2]\n",
        "N -> 'man' [0.5] | 'telescope' [0.5]\n",
        "VP -> VP PP [0.05] | V NP [0.9] | V [0.05]\n",
        "V -> 'ate' [0.2] | 'saw' [0.8]\n",
        "PP -> P NP [1.0]\n",
        "P -> 'with' [0.70] | 'in' [0.30]\n",
        "\"\"\")\n",
        "\n",
        "print(pcfg2)\n",
        "\n",
        "text = \"I saw the man with a telescope\"\n",
        "text_tokens = nltk.word_tokenize(text)\n",
        "\n",
        "viterbi_parser = nltk.ViterbiParser(pcfg2,trace=0)\n",
        "\n",
        "# Calculate the probability of the most probable parse tree\n",
        "prob = None\n",
        "for tree in viterbi_parser.parse(text_tokens):\n",
        "    prob = tree.prob()\n",
        "    break\n",
        "print(\"Parsing probability:\", prob)\n",
        "\n",
        "# print parsing tree\n",
        "trees = viterbi_parser.parse(text_tokens)\n",
        "for tree in trees:\n",
        "    print(tree)\n",
        "    #tree.draw()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8yNYsG-j2q5",
        "outputId": "bc1c9aea-b0dd-48fc-ff19-8aea0ac278c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grammar with 17 productions (start state = S)\n",
            "    S -> NP VP [1.0]\n",
            "    NP -> Det N [0.4]\n",
            "    NP -> NP PP [0.25]\n",
            "    NP -> 'John' [0.05]\n",
            "    NP -> 'I' [0.3]\n",
            "    Det -> 'the' [0.8]\n",
            "    Det -> 'a' [0.2]\n",
            "    N -> 'man' [0.5]\n",
            "    N -> 'telescope' [0.5]\n",
            "    VP -> VP PP [0.05]\n",
            "    VP -> V NP [0.9]\n",
            "    VP -> V [0.05]\n",
            "    V -> 'ate' [0.2]\n",
            "    V -> 'saw' [0.8]\n",
            "    PP -> P NP [1.0]\n",
            "    P -> 'with' [0.7]\n",
            "    P -> 'in' [0.3]\n",
            "Parsing probability: 0.00024192000000000007\n",
            "(S\n",
            "  (NP I)\n",
            "  (VP\n",
            "    (V saw)\n",
            "    (NP\n",
            "      (NP (Det the) (N man))\n",
            "      (PP (P with) (NP (Det a) (N telescope)))))) (p=0.00024192)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nwT9cT_UkW2f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}