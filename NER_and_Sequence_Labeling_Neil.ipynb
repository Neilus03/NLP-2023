{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neilus03/NLP-2023/blob/main/NER_and_Sequence_Labeling_Neil.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Sequence Labeling - NER\n",
        "\n",
        "The extraction of relevant information from historical handwritten document collections is one of the key steps in order to make these manuscripts available for access and searches. In this context, instead of a pure transcription, the objective is to move towards document understanding. Concretely, the aim is to detect the named entities and assign each of them a semantic category, such as family names, places, occupations, etc.\n",
        "\n",
        "\n",
        "A typical application scenario of named entity recognition is demographic documents, since they contain people's names, birthplaces, occupations, etc. In this scenario, the extraction of the key contents and its storage in databases allows the access to their contents and envision innovative services based in genealogical, social or demographic searches.\n",
        "\n",
        "<p style = 'text-align: center'>\n",
        "<img src = \"http://dag.cvc.uab.es/wp-content/uploads/2016/07/esposalla_detall.jpg\">\n",
        "</p>\n",
        "\n",
        "For further doubts and questions, refer to oriol.ramos@uab.cat and alicia.fornes@uab.cat.\n",
        "\n",
        "Usage of Google Colab is not mandatory, but highly recommended as most of the behaviors are expected for a Linux VM with IPython bindings.\n",
        "\n",
        "## First, we will install the unmet dependencies.\n",
        "\n",
        "This will download some packages and the required data, it may take a while."
      ],
      "metadata": {
        "id": "iXYMGLM2UTG1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "R8Rcfr3oUAms"
      },
      "outputs": [],
      "source": [
        "#@title \n",
        "from IPython.display import clear_output\n",
        "\n",
        "!git clone https://github.com/EauDeData/nlp-resources\n",
        "!cp -r nlp-resources/ resources/\n",
        "!rm -rf nlp-resources/\n",
        "\n",
        "\n",
        "!pip install nltk \n",
        "!pip install git+https://github.com/MeMartijn/updated-sklearn-crfsuite\n",
        "clear_output()\n",
        "\n",
        "from typing import * \n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "import copy\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "import sklearn_crfsuite as crfs\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "from resources.data.dataloaders import EsposallesTextDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Curation\n",
        "Loading the dataset"
      ],
      "metadata": {
        "id": "2LbPYoxkYGUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "train_loader = EsposallesTextDataset('resources/data/esposalles/') \n",
        "test_loader = copy.deepcopy(train_loader)\n",
        "test_loader.test()"
      ],
      "metadata": {
        "id": "NRLKbU-4UQ8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of data from each loader:\n",
        "> Format string: ```word```:```label```\n"
      ],
      "metadata": {
        "id": "JzOLIKMGUGAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print([f\"{x}:{y}\" for x,y in zip(*train_loader[0])])\n",
        "print([f\"{x}:{y}\" for x,y in zip(*test_loader[0])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6nElJ2-ZCJe",
        "outputId": "4674b89f-dcae-4fb5-9581-7724b058f147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dilluns:other', 'a:other', '5:other', 'rebere:other', 'de:other', 'Hyacinto:name', 'Boneu:surname', 'hortola:occupation', 'de:other', 'Bara:location', 'fill:other', 'de:other', 'Juan:name', 'Boneu:surname', 'parayre:occupation', 'defunct:other', 'y:other', 'de:other', 'Maria:name', 'ab:other', 'Anna:name', 'donsella:state', 'filla:other', 'de:other', 't:name', 'Cases:surname', 'pages:occupation', 'de:other', 'Bara:location', 'defunct:other', 'y:other', 'de:other', 'Peyrona:name']\n",
            "['Divendres:other', 'a:other', '18:other', 'rebere:other', 'de:other', 'Juan:name', 'Torres:surname', 'pages:occupation', 'habitant:other', 'en:other', 'Sabadell:location', 'fill:other', 'de:other', 'Bernat:name', 'Torres:surname', 'pages:occupation', 'de:other', 'Moya:location', 'bisbat:location', 'de:location', 'Vich:location', 'y:other', 'de:other', 'Antiga:name', 'defucts:other', 'ab:other', 'Margarida:name', 'donsella:state', 'filla:other', 'de:other', 'Juan:name', 'Argemir:surname', 'pages:occupation', 'de:other', 'Sabadell:location', 'y:other', 'de:other', 'Aldonsa:name', 'defuncts:other']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the dataset is correctly downloaded you will see two different samples above, and both tests passed below."
      ],
      "metadata": {
        "id": "PXOg5M3-lg5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "# Dataset ckeck\n",
        "\n",
        "for idx in range(len(train_loader)):\n",
        "\n",
        "  x, y = train_loader[idx]\n",
        "  if len(x) != len(y): \n",
        "    print('train_set test not passed')\n",
        "    break\n",
        "\n",
        "else: print('train_set test passed')\n",
        "\n",
        "for idx in range(len(test_loader)):\n",
        "\n",
        "  x, y = test_loader[idx]\n",
        "  if len(x) != len(y):\n",
        "    print('test_set test not passed')\n",
        "    break\n",
        "\n",
        "else: print('test_set test passed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "K7_mFDqOkcnW",
        "outputId": "0ace8a37-bb9a-4ca7-fbfd-64c6411418da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_set test passed\n",
            "test_set test passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since most of the computation won't be done with strings, the following function will create a Look Up Table (LUT) that transforms string tokens into ```int``` tokens. "
      ],
      "metadata": {
        "id": "nqp5OuN8YTwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tokens_lut(train_dataset) -> Dict:\n",
        "  '''\n",
        "  Input:\n",
        "    train_dataset: Training dataset. \n",
        "\n",
        "    Don't tokenize test_set as later on,\n",
        "       we will be considering out-of-vocabulary words as <unk> tokens.\n",
        "\n",
        "    NOTE: Tokens MUST be lowered (.lower()) before considering them. \n",
        "\n",
        "  Ouput:\n",
        "    LUT[Dict]: {\n",
        "      word1: 0,\n",
        "      word2: 1,\n",
        "        ...\n",
        "      wordn: n - 1\n",
        "    }\n",
        "\n",
        "  '''\n",
        "\n",
        "  pass\n",
        "\n",
        "  \n",
        "LUT = create_tokens_lut(train_loader)"
      ],
      "metadata": {
        "id": "rt-8QpTzYx2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_oov_words(LUT = LUT, test_set = test_loader):\n",
        "  pass\n",
        "\n",
        "print(list(check_oov_words()))\n"
      ],
      "metadata": {
        "id": "fxkJj8tDe5WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to batch computation of some modules, sequences must have constant length. As a common practice, we will create three new tokens ```<bos>``` and ```<eos>``` for the start and the end of a given sequence and ```<unk>``` for unkown tokens in the application (test) layer or 0 padding during the training. Manually add those tokens to the ```LUT```. \n",
        " \n",
        "\n",
        "Under those constraints, fill the corresponding functions that will post-process each batch. Feel free to code more post-processing functions if you need it.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7zHKqdlAUtly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LUT['<unk>'] = len(LUT) + 1\n",
        "LUT['<bos>'] = len(LUT) + 1\n",
        "LUT['<eos>'] = len(LUT) + 1"
      ],
      "metadata": {
        "id": "tnpVY5K7iJ9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQUENCE_LENGTH = 50\n",
        "def complete_seq(X) -> List[List]:\n",
        "  \n",
        "  '''\n",
        "\n",
        "    Input: \n",
        "      X: A batch of N sequences [\n",
        "        [word1, ..., wordn],\n",
        "        [word1, ..., wordm]\n",
        "      ]\n",
        "\n",
        "    Output:\n",
        "      A batch of N sequences with MAX_SEQUENCE_LENGTH tokens.\n",
        "        - The starting token will always be <sos>\n",
        "        - The last 'real' token <eos>\n",
        "        - Tokens from <eos> until MAX_SEQUENCE_LENGTH will be <unk> as 0 padding.\n",
        "\n",
        "  '''\n",
        "  pass\n",
        "\n",
        "def post_process(X, functions = [complete_seq,]):\n",
        "  for f in functions: X = f(X)\n",
        "  return X"
      ],
      "metadata": {
        "id": "oj0cq0SGUsgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NER - Baseline Approach\n",
        "\n",
        "The first approach we will try is based on computing the probabilities for each word in our training corpus. This means computing the most likely category for each word in the dictionary.\n",
        "\n",
        "Compute the test categories predictions and measure the performance for this simple model."
      ],
      "metadata": {
        "id": "GKuJPkJOanmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_emissions_dict(dataloader) -> Dict:\n",
        "  '''\n",
        "\n",
        "    Given the train loader ```dataloader```\n",
        "     this function will compute the max likelihood dictionary for each word.\n",
        "\n",
        "  Input:\n",
        "    dataloader: train loader with EsposallesTextDataset\n",
        "  \n",
        "  Outputs:\n",
        "    Dict: {\n",
        "      pagès: {name: X occupation: X}, # REMEMBER TO LOWER YOUR TOKENS!\n",
        "            ...\n",
        "      LUT - wordn: {category: x%, ...}\n",
        "    }\n",
        "\n",
        "  '''\n",
        "\n",
        "  pass"
      ],
      "metadata": {
        "id": "rYA9D-twbego"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "priors = compute_emissions_dict(train_loader)"
      ],
      "metadata": {
        "id": "uFQe-5VykF9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, as an example, your emissions dictionary should yield the following emission:\n",
        "\n",
        "$P(location |$ ```Prats``` $) = 18\\%$\n",
        "\n",
        "$P(surname |$ ```Prats``` $) = 72\\%$\n",
        "\n",
        "$P(other |$ ```Prats``` $) = 9\\%$"
      ],
      "metadata": {
        "id": "OozkEhtlQow-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "priors['prats']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEFUzlRpQmTa",
        "outputId": "7fe36f4d-6230-4b7e-e144-1244eb1b61a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'location': 0.1818, 'surname': 0.7273, 'other': 0.0909}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method has its limitations in terms of lack of context and, therefore, low expresivity. \n",
        "\n",
        "The following function will compute the confusion matrix for the predictions in the ```test_set``` in order to find the most problematic words. \n",
        "\n",
        "* What do they all have in common? \n",
        "* What kind of words are the least performers?\n",
        "* What's your solution for out-of-vocabulary words? Can you provide a prediction for those?"
      ],
      "metadata": {
        "id": "p1JaHhJvcwK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_test_set(emissions, test_set):\n",
        "  \n",
        "  '''\n",
        "\n",
        "  s: casament eduard pages\n",
        "\n",
        "  prediccio: [None, nom, ofici]\n",
        "\n",
        "  Important: \n",
        "    Remember to check if you can provide a label for each word (OOVs?).\n",
        "    What's your solution for those you cannot classify? Justify.\n",
        "\n",
        "      tip: be as creative as you want.\n",
        "\n",
        "  '''\n",
        "  predictions = []\n",
        "  pass\n",
        "\n",
        "\n",
        "predictions = predict_test_set(priors, test_loader)\n",
        "\n",
        "def find_common_errors(x_test: List[List], y_pred: List[List], y_true: List[List]) -> Dict:\n",
        "\n",
        "  '''\n",
        "    Input: \n",
        "      x_test: A list with each sample in the corpus with the words for which we\n",
        "ran each prediction\n",
        "          [\n",
        "           ['lorem', 'ipsum', 'dolor', 'sit', 'amet'],\n",
        "           ['Hello', 'world', '!!!'],\n",
        "          ]\n",
        "      \n",
        "      y_pred: A list with the predicted labels for each word in x_test corpus.\n",
        "          [\n",
        "           ['1', '0', '0', '1', '2'],\n",
        "           ['2', '1', '0'],\n",
        "          ]\n",
        "      \n",
        "      y_true: GT for the x_test sample\n",
        "          [\n",
        "           ['0', '0', '0', '1', '2'],\n",
        "           ['0', '1', '0'],\n",
        "          ]\n",
        "    {\n",
        "      pages: [{'pred': prediction, gt: label}, {'pred': prediction, 'gt': label}, ...]\n",
        "    }\n",
        "  '''\n",
        "\n",
        "  errors = {}\n",
        "  pass\n",
        "\n",
        "def compute_token_precision(x_test: List[List], y_pred: List[List], y_true: List[List]):\n",
        "    pass\n",
        "\n"
      ],
      "metadata": {
        "id": "lDQeZ1_Zcbqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_common_errors([test_loader[idx][0] for idx in range(len(test_loader))], predictions, [test_loader[idx][1] for idx in range(len(test_loader))])['Esteva']\n",
        "compute_token_precision([test_loader[idx][0] for idx in range(len(test_loader))], predictions, [test_loader[idx][1] for idx in range(len(test_loader))])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-bjHuqWLH_w",
        "outputId": "cfa9d12b-41db-4178-e9a2-56e539f6682a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8834888960411973"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze the results for the common errors."
      ],
      "metadata": {
        "id": "wgH5jj9za5EH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusions\n",
        "\n",
        "Here, write a brief conclusion for this notebook reffering to the main differences, advantages and disadvantages for each approach.\n"
      ],
      "metadata": {
        "id": "Qa8EqtjvisI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Your conclusions here\n",
        "\n"
      ],
      "metadata": {
        "id": "Ak0r9CPEjEb0"
      }
    }
  ]
}